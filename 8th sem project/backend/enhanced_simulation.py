"""
Enhanced Async Simulation Engine
Generates >150 req/sec with proper anomaly injection for all endpoints
"""
import asyncio
import random
import time
from datetime import datetime
from typing import List, Dict
from enum import Enum
from database import SessionLocal, APILog, AnomalyLog
from anomaly_detection import anomaly_detector
from resolution_engine import resolution_engine

class AnomalyType(Enum):
    LATENCY_SPIKE = "latency_spike"
    ERROR_SPIKE = "error_spike"
    TRAFFIC_BURST = "traffic_burst"
    TIMEOUT = "timeout"
    RESOURCE_EXHAUSTION = "resource_exhaustion"

class Severity(Enum):
    CRITICAL = "CRITICAL"
    HIGH = "HIGH"
    MEDIUM = "MEDIUM"
    LOW = "LOW"

class EnhancedSimulationEngine:
    """High-performance async simulation engine"""
    
    # All endpoints with their assigned anomaly types
    ENDPOINT_ANOMALIES = {
        '/sim/payment': (AnomalyType.TIMEOUT, Severity.CRITICAL),
        '/sim/search': (AnomalyType.LATENCY_SPIKE, Severity.HIGH),
        '/sim/login': (AnomalyType.ERROR_SPIKE, Severity.HIGH),
        '/sim/profile': (AnomalyType.TRAFFIC_BURST, Severity.MEDIUM),
        '/sim/signup': (AnomalyType.RESOURCE_EXHAUSTION, Severity.CRITICAL),
        '/sim/logout': (AnomalyType.LATENCY_SPIKE, Severity.LOW)
    }
    
    def __init__(self):
        self.active = False
        self.total_requests = 0
        self.start_time = None
        self.stats = {
            'total_requests': 0,
            'anomalies_injected': 0,
            'anomalies_detected': 0,
            'windows_processed': 0,
            'by_endpoint': {}
        }
        self.websocket_manager = None
        
    def set_websocket_manager(self, manager):
        """Set websocket manager for real-time updates"""
        self.websocket_manager = manager
        
    def generate_anomalous_request(self, endpoint: str, anomaly_type: AnomalyType, severity: Severity) -> Dict:
        """Generate request with specific anomaly"""
        base_time = datetime.utcnow()
        
        # Anomaly-specific parameters
        if anomaly_type == AnomalyType.LATENCY_SPIKE:
            severity_multipliers = {
                Severity.CRITICAL: (5000, 8000),
                Severity.HIGH: (3000, 5000),
                Severity.MEDIUM: (1500, 3000),
                Severity.LOW: (800, 1500)
            }
            response_min, response_max = severity_multipliers[severity]
            response_time = random.uniform(response_min, response_max)
            status_code = random.choices([200, 500, 503], weights=[60, 30, 10])[0]
            error_rate = 0.15
            impact_score = 0.7 if severity in [Severity.CRITICAL, Severity.HIGH] else 0.4
            
        elif anomaly_type == AnomalyType.ERROR_SPIKE:
            severity_error_rates = {
                Severity.CRITICAL: 0.85,
                Severity.HIGH: 0.65,
                Severity.MEDIUM: 0.45,
                Severity.LOW: 0.25
            }
            error_rate = severity_error_rates[severity]
            response_time = random.uniform(200, 800)
            status_code = random.choices([500, 503, 502, 504, 200], weights=[40, 30, 20, 10, 10])[0]
            impact_score = 0.85 if severity in [Severity.CRITICAL, Severity.HIGH] else 0.5
            
        elif anomaly_type == AnomalyType.TIMEOUT:
            response_time = random.uniform(8000, 15000)
            status_code = random.choices([504, 408, 503], weights=[60, 30, 10])[0]
            error_rate = 0.9
            impact_score = 0.95
            
        elif anomaly_type == AnomalyType.TRAFFIC_BURST:
            response_time = random.uniform(500, 1500)
            status_code = random.choices([429, 503, 200], weights=[40, 30, 30])[0]
            error_rate = 0.3
            impact_score = 0.6
            
        elif anomaly_type == AnomalyType.RESOURCE_EXHAUSTION:
            response_time = random.uniform(3000, 7000)
            status_code = random.choices([503, 507, 500, 200], weights=[40, 30, 20, 10])[0]
            error_rate = 0.7
            impact_score = 0.9
            
        else:
            response_time = random.uniform(50, 250)
            status_code = 200
            error_rate = 0.02
            impact_score = 0.1
            
        payload_size = random.randint(500, 8000) if anomaly_type == AnomalyType.RESOURCE_EXHAUSTION else random.randint(500, 2000)
        
        return {
            'timestamp': base_time,
            'endpoint': endpoint,
            'method': 'POST' if endpoint in ['/sim/payment', '/sim/login', '/sim/signup'] else 'GET',
            'response_time_ms': response_time,
            'status_code': status_code,
            'payload_size': payload_size,
            'ip_address': f"192.168.{random.randint(1, 255)}.{random.randint(1, 255)}",
            'user_id': f"user_{random.randint(1000, 9999)}",
            'is_simulation': True,
            '_anomaly_metadata': {
                'type': anomaly_type.value,
                'severity': severity.value,
                'error_rate': error_rate,
                'impact_score': impact_score,
                'duration_seconds': random.uniform(15, 60)
            }
        }
    
    def generate_normal_request(self, endpoint: str) -> Dict:
        """Generate normal request"""
        return {
            'timestamp': datetime.utcnow(),
            'endpoint': endpoint,
            'method': 'POST' if endpoint in ['/sim/payment', '/sim/login', '/sim/signup'] else 'GET',
            'response_time_ms': random.uniform(50, 250),
            'status_code': random.choices([200, 400, 404], weights=[95, 3, 2])[0],
            'payload_size': random.randint(500, 2000),
            'ip_address': f"192.168.{random.randint(1, 255)}.{random.randint(1, 255)}",
            'user_id': f"user_{random.randint(1000, 9999)}",
            'is_simulation': True,
            '_anomaly_metadata': None
        }
    
    async def generate_request_batch(self, target_rps: int = 200) -> List[Dict]:
        """Generate batch of requests distributed across all endpoints"""
        requests = []
        endpoints = list(self.ENDPOINT_ANOMALIES.keys())
        
        # Distribute requests across endpoints
        reqs_per_endpoint = target_rps // len(endpoints)
        
        for endpoint in endpoints:
            anomaly_type, severity = self.ENDPOINT_ANOMALIES[endpoint]
            
            for _ in range(reqs_per_endpoint):
                # 30% chance of anomaly injection for continuous anomaly traffic
                if random.random() < 0.3:
                    request = self.generate_anomalous_request(endpoint, anomaly_type, severity)
                    self.stats['anomalies_injected'] += 1
                else:
                    request = self.generate_normal_request(endpoint)
                    
                requests.append(request)
                
                # Track endpoint stats
                if endpoint not in self.stats['by_endpoint']:
                    self.stats['by_endpoint'][endpoint] = {'total': 0, 'anomalies': 0}
                self.stats['by_endpoint'][endpoint]['total'] += 1
                if request['_anomaly_metadata']:
                    self.stats['by_endpoint'][endpoint]['anomalies'] += 1
        
        return requests
    
    async def persist_requests(self, requests: List[Dict]):
        """Persist requests to database asynchronously"""
        db = SessionLocal()
        try:
            for req in requests:
                log_entry = APILog(
                    timestamp=req['timestamp'],
                    endpoint=req['endpoint'],
                    method=req['method'],
                    response_time_ms=req['response_time_ms'],
                    status_code=req['status_code'],
                    payload_size=req['payload_size'],
                    ip_address=req['ip_address'],
                    user_id=req['user_id'],
                    is_simulation=True
                )
                db.add(log_entry)
            
            db.commit()
            self.total_requests += len(requests)
            self.stats['total_requests'] = self.total_requests
        except Exception as e:
            print(f"âŒ Error persisting requests: {e}")
            db.rollback()
        finally:
            db.close()
    
    async def detect_and_broadcast_anomalies(self):
        """Run detection and broadcast anomalies via websocket"""
        from feature_engineering import extract_features_from_logs
        
        db = SessionLocal()
        try:
            # Detect anomalies for each endpoint separately
            for endpoint in self.ENDPOINT_ANOMALIES.keys():
                features = extract_features_from_logs(
                    time_window_minutes=1, 
                    is_simulation=True,
                    specific_endpoint=endpoint
                )
                
                if not features:
                    continue
                
                self.stats['windows_processed'] += 1
                
                # Run deterministic detection
                detection_result = anomaly_detector.detect(features)
                
                if not detection_result['is_anomaly']:
                    continue
                
                self.stats['anomalies_detected'] += 1
                
                # Get assigned anomaly type
                assigned_type, assigned_severity = self.ENDPOINT_ANOMALIES[endpoint]
                anomaly_type = detection_result.get('anomaly_type', assigned_type.value)
                severity = detection_result.get('severity', assigned_severity.value)
                
                # Generate resolutions
                resolutions = resolution_engine.generate_resolutions(anomaly_type, severity)
                
                # Persist anomaly
                anomaly_log = AnomalyLog(
                    endpoint=features['endpoint'],
                    method=features['method'],
                    risk_score=detection_result.get('confidence', 0.8) * 100,
                    priority=severity,
                    failure_probability=detection_result['failure_probability'],
                    anomaly_score=detection_result.get('confidence', 0.8),
                    is_anomaly=True,
                    usage_cluster=2,
                    req_count=features['req_count'],
                    error_rate=features['error_rate'],
                    avg_response_time=features['avg_response_time'],
                    max_response_time=features['max_response_time'],
                    payload_mean=features['payload_mean'],
                    unique_endpoints=features['unique_endpoints'],
                    repeat_rate=features['repeat_rate'],
                    status_entropy=features['status_entropy'],
                    anomaly_type=anomaly_type,
                    severity=severity,
                    duration_seconds=60.0,
                    impact_score=detection_result['impact_score'],
                    is_simulation=True
                )
                db.add(anomaly_log)
                db.commit()
                db.refresh(anomaly_log)
                
                # Broadcast via websocket
                if self.websocket_manager:
                    await self.websocket_manager.broadcast({
                        'type': 'anomaly',
                        'data': {
                            'id': anomaly_log.id,
                            'timestamp': anomaly_log.timestamp.isoformat(),
                            'endpoint': anomaly_log.endpoint,
                            'method': anomaly_log.method,
                            'anomaly_type': anomaly_type,
                            'severity': severity,
                            'duration_seconds': 60.0,
                            'impact_score': detection_result['impact_score'],
                            'failure_probability': detection_result['failure_probability'],
                            'risk_score': anomaly_log.risk_score,
                            'priority': anomaly_log.priority,
                            'resolutions': resolutions[:5],
                            'is_anomaly': True
                        }
                    })
                
                print(f"ðŸš¨ Anomaly Detected: {endpoint} | Type: {anomaly_type} | Severity: {severity} | Impact: {detection_result['impact_score']:.2f}")
                
        except Exception as e:
            print(f"âŒ Error in detection: {e}")
            import traceback
            traceback.print_exc()
        finally:
            db.close()
    
    async def run(self, duration_seconds: int = 60, target_rps: int = 200):
        """Run high-speed simulation with continuous anomaly injection"""
        self.active = True
        self.start_time = time.time()
        self.total_requests = 0
        self.stats = {
            'total_requests': 0,
            'anomalies_injected': 0,
            'anomalies_detected': 0,
            'windows_processed': 0,
            'by_endpoint': {}
        }
        
        print(f"\n{'='*80}")
        print(f"ðŸš€ ENHANCED SIMULATION STARTED")
        print(f"{'='*80}")
        print(f"   Target RPS: {target_rps}")
        print(f"   Duration: {duration_seconds}s")
        print(f"   Endpoints: {len(self.ENDPOINT_ANOMALIES)}")
        print(f"{'='*80}\n")
        
        end_time = time.time() + duration_seconds
        detection_interval = 10  # Run detection every 10 seconds
        last_detection = time.time()
        
        try:
            while self.active and time.time() < end_time:
                batch_start = time.time()
                
                # Generate and persist requests
                requests = await self.generate_request_batch(target_rps)
                await self.persist_requests(requests)
                
                # Run detection periodically
                if time.time() - last_detection >= detection_interval:
                    await self.detect_and_broadcast_anomalies()
                    last_detection = time.time()
                
                # Calculate metrics
                elapsed = time.time() - self.start_time
                current_rps = self.total_requests / elapsed if elapsed > 0 else 0
                
                print(f"âš¡ Batch: {len(requests)} reqs | Total: {self.total_requests} | "
                      f"RPS: {current_rps:.1f} | Anomalies: {self.stats['anomalies_detected']}")
                
                # Sleep to maintain target rate (1 second per batch)
                batch_time = time.time() - batch_start
                sleep_time = max(0, 1.0 - batch_time)
                if sleep_time > 0:
                    await asyncio.sleep(sleep_time)
                    
        except Exception as e:
            print(f"âŒ Simulation error: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # Final detection pass
            await self.detect_and_broadcast_anomalies()
            
            self.active = False
            elapsed_total = time.time() - self.start_time
            final_rps = self.total_requests / elapsed_total if elapsed_total > 0 else 0
            
            print(f"\n{'='*80}")
            print(f"âœ… SIMULATION COMPLETED")
            print(f"{'='*80}")
            print(f"   Total Requests: {self.total_requests}")
            print(f"   Duration: {elapsed_total:.2f}s")
            print(f"   Avg RPS: {final_rps:.1f}")
            print(f"   Anomalies Injected: {self.stats['anomalies_injected']}")
            print(f"   Anomalies Detected: {self.stats['anomalies_detected']}")
            print(f"   Detection Rate: {(self.stats['anomalies_detected'] / self.stats['anomalies_injected'] * 100) if self.stats['anomalies_injected'] > 0 else 0:.1f}%")
            print(f"{'='*80}\n")
            
            # Print per-endpoint stats
            print("Per-Endpoint Statistics:")
            for endpoint, stats in self.stats['by_endpoint'].items():
                print(f"  {endpoint}: {stats['total']} reqs, {stats['anomalies']} anomalies")
    
    def stop(self):
        """Stop simulation"""
        self.active = False
        
    def get_stats(self) -> Dict:
        """Get current statistics"""
        elapsed = time.time() - self.start_time if self.start_time else 0
        return {
            **self.stats,
            'active': self.active,
            'duration': elapsed,
            'rps': self.total_requests / elapsed if elapsed > 0 else 0
        }


# Global simulation engine instance
enhanced_simulation_engine = EnhancedSimulationEngine()
